{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425e6c65",
   "metadata": {},
   "source": [
    "# This is going to test the dingomodel we currently have using data thats been zero_padded to keep the same length\n",
    "\n",
    "I think this will probably not have good results, but we can find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1daa8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JHPY import *\n",
    "from JHPY import DINGOModel\n",
    "from typing import Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a8f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloaders(load_path: str, batch_size: int = None, shuffle_train: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Load previously saved datasets and create DataLoaders.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    load_path : str\n",
    "        Path to the saved data file (created with save_dataloaders)\n",
    "    batch_size : int, optional\n",
    "        Batch size for DataLoaders. If None, uses the batch_size from metadata.\n",
    "    shuffle_train : bool\n",
    "        Whether to shuffle training data. Default: True\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with 'train_loader', 'val_loader', 'test_loader', 'metadata'\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Save after generation\n",
    "    >>> result = pycbc_data_generator(config, num_samples=1000)\n",
    "    >>> save_dataloaders(result, 'my_data.pt')\n",
    "    >>> \n",
    "    >>> # Later, load the data\n",
    "    >>> loaded = load_dataloaders('my_data.pt')\n",
    "    >>> train_loader = loaded['train_loader']\n",
    "    >>> val_loader = loaded['val_loader']\n",
    "    >>> test_loader = loaded['test_loader']\n",
    "    \"\"\"\n",
    "    print(f\"Loading datasets from {load_path}...\")\n",
    "    \n",
    "    # Load the saved data\n",
    "    save_data = torch.load(load_path, weights_only=False)\n",
    "    \n",
    "    X = save_data['X']\n",
    "    y = save_data['y']\n",
    "    train_indices = save_data['train_indices']\n",
    "    val_indices = save_data['val_indices']\n",
    "    test_indices = save_data['test_indices']\n",
    "    metadata = save_data['metadata']\n",
    "    \n",
    "    # Use saved batch_size if not provided\n",
    "    if batch_size is None:\n",
    "        batch_size = metadata['batch_size']\n",
    "    else:\n",
    "        # Update metadata with new batch_size\n",
    "        metadata = metadata.copy()\n",
    "        metadata['batch_size'] = batch_size\n",
    "    \n",
    "    print(f\"  Tensors: X={X.shape}, y={y.shape}\")\n",
    "    print(f\"  Splits: train={len(train_indices)}, val={len(val_indices)}, test={len(test_indices)}\")\n",
    "    \n",
    "    # Recreate the dataset\n",
    "    full_dataset = TensorDataset(X, y)\n",
    "    \n",
    "    # Create subsets using the saved indices\n",
    "    from torch.utils.data import Subset\n",
    "    train_data = Subset(full_dataset, train_indices)\n",
    "    val_data = Subset(full_dataset, val_indices)\n",
    "    test_data = Subset(full_dataset, test_indices)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nReady! DataLoaders with batch_size={batch_size}\")\n",
    "    \n",
    "    return {\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'test_loader': test_loader,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b462d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets from data_loaders_zero_padded.pt...\n",
      "  Tensors: X=torch.Size([10000, 2, 6274]), y=torch.Size([10000, 2])\n",
      "  Splits: train=8000, val=1000, test=1000\n",
      "\n",
      "Ready! DataLoaders with batch_size=128\n",
      "Creating DINGOModel with inferred dimensions:\n",
      "  data_dim (time length per detector): 6274\n",
      "  num_detectors: 2\n",
      "  param_dim: 2\n",
      "  context_dim: 256\n",
      "  num_flow_layers: 10\n",
      "  multi_detector_mode: concatenate\n"
     ]
    }
   ],
   "source": [
    "data_loaders = load_dataloaders(\"data_loaders_zero_padded.pt\", batch_size=128)\n",
    "\n",
    "model = create_dingo_from_data(data_loaders, context_dim=256, num_flow_layers=10, hidden_dim=1024, multi_detector_mode='concatenate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc26bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, training: 100%|██████████| 63/63 [00:26<00:00,  2.34it/s]\n",
      "Epoch 1, validation: 100%|██████████| 8/8 [00:00<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  1]\n",
      "Training - Log Prob: -24.1018\n",
      "Validation - Log Prob: -7.6950\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, training: 100%|██████████| 63/63 [00:26<00:00,  2.34it/s]\n",
      "Epoch 2, validation: 100%|██████████| 8/8 [00:00<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  2]\n",
      "Training - Log Prob: -7.6375\n",
      "Validation - Log Prob: -7.5989\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, training: 100%|██████████| 63/63 [00:26<00:00,  2.37it/s]\n",
      "Epoch 3, validation: 100%|██████████| 8/8 [00:00<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  3]\n",
      "Training - Log Prob: -7.5974\n",
      "Validation - Log Prob: -7.5550\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, training: 100%|██████████| 63/63 [00:26<00:00,  2.34it/s]\n",
      "Epoch 4, validation: 100%|██████████| 8/8 [00:00<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  4]\n",
      "Training - Log Prob: -7.5388\n",
      "Validation - Log Prob: -7.5208\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, training: 100%|██████████| 63/63 [00:27<00:00,  2.32it/s]\n",
      "Epoch 5, validation: 100%|██████████| 8/8 [00:00<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  5]\n",
      "Training - Log Prob: -7.5340\n",
      "Validation - Log Prob: -7.5161\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, training: 100%|██████████| 63/63 [00:27<00:00,  2.33it/s]\n",
      "Epoch 6, validation: 100%|██████████| 8/8 [00:00<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  6]\n",
      "Training - Log Prob: -7.5289\n",
      "Validation - Log Prob: -7.5359\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, training: 100%|██████████| 63/63 [00:26<00:00,  2.34it/s]\n",
      "Epoch 7, validation: 100%|██████████| 8/8 [00:00<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  7]\n",
      "Training - Log Prob: -7.5270\n",
      "Validation - Log Prob: -7.4815\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, training: 100%|██████████| 63/63 [00:27<00:00,  2.30it/s]\n",
      "Epoch 8, validation: 100%|██████████| 8/8 [00:00<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  8]\n",
      "Training - Log Prob: -7.5195\n",
      "Validation - Log Prob: -7.5051\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, training: 100%|██████████| 63/63 [00:27<00:00,  2.27it/s]\n",
      "Epoch 9, validation: 100%|██████████| 8/8 [00:00<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  9]\n",
      "Training - Log Prob: -7.5076\n",
      "Validation - Log Prob: -7.5286\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, training: 100%|██████████| 63/63 [00:27<00:00,  2.32it/s]\n",
      "Epoch 10, validation: 100%|██████████| 8/8 [00:00<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10]\n",
      "Training - Log Prob: -7.5183\n",
      "Validation - Log Prob: -7.4951\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, training: 100%|██████████| 63/63 [00:26<00:00,  2.36it/s]\n",
      "Epoch 11, validation: 100%|██████████| 8/8 [00:00<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 11]\n",
      "Training - Log Prob: -7.5233\n",
      "Validation - Log Prob: -7.5197\n",
      "Learning rate reduced. Loading best model from Dingo.pt\n",
      "Best model loaded, resuming training\n",
      "\n",
      "Current learning rates: [0.00025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, training: 100%|██████████| 63/63 [00:26<00:00,  2.39it/s]\n",
      "Epoch 12, validation: 100%|██████████| 8/8 [00:00<00:00, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12]\n",
      "Training - Log Prob: -7.4876\n",
      "Validation - Log Prob: -7.4838\n",
      "Current learning rates: [0.00025]\n",
      "No improvement in validation log prob in last 5 epochs \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "training_stuff = train_npe_model(model, optimizer, 50, data_loaders[\"train_loader\"], data_loaders[\"val_loader\"], scheduler=scheduler, patience=5, dropout_rate=0.1, save_best_model=True, model_path=\"Dingo.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca4be55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 10000 samples for training\n",
      "data generated\n"
     ]
    }
   ],
   "source": [
    "sin_data = generate_sine_data(phase_low=0,phase_high=0,num_points=6274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446a0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'data_dim': 6274,\n",
    "            'param_dim': 3,\n",
    "            'context_dim': 256,\n",
    "            'num_flow_layers': 10,\n",
    "            'hidden_dim': 1024,\n",
    "        }\n",
    "\n",
    "sin_model = DINGOModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230b4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, training: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "Epoch 1, validation: 100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  1]\n",
      "Training - Log Prob: -1.6919\n",
      "Validation - Log Prob: 3.1525\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, training: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "Epoch 2, validation: 100%|██████████| 4/4 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  2]\n",
      "Training - Log Prob: 3.5562\n",
      "Validation - Log Prob: 4.2544\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, training: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "Epoch 3, validation: 100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  3]\n",
      "Training - Log Prob: 4.2017\n",
      "Validation - Log Prob: 4.8206\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, training: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]\n",
      "Epoch 4, validation: 100%|██████████| 4/4 [00:00<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  4]\n",
      "Training - Log Prob: 4.7273\n",
      "Validation - Log Prob: 4.4464\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, training: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "Epoch 5, validation: 100%|██████████| 4/4 [00:00<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  5]\n",
      "Training - Log Prob: 4.7836\n",
      "Validation - Log Prob: 5.4061\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, training: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "Epoch 6, validation: 100%|██████████| 4/4 [00:00<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  6]\n",
      "Training - Log Prob: 5.1034\n",
      "Validation - Log Prob: 5.9813\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, training: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "Epoch 7, validation: 100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  7]\n",
      "Training - Log Prob: 5.0228\n",
      "Validation - Log Prob: 5.7739\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, training: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "Epoch 8, validation: 100%|██████████| 4/4 [00:00<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  8]\n",
      "Training - Log Prob: 5.5380\n",
      "Validation - Log Prob: 5.6534\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, training: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "Epoch 9, validation: 100%|██████████| 4/4 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch  9]\n",
      "Training - Log Prob: 5.9277\n",
      "Validation - Log Prob: 6.7346\n",
      "Current learning rates: [0.0005]\n",
      "New best validation performance \n",
      "\n",
      "Model checkpoint saved to Dingo_sin.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, training: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "Epoch 10, validation: 100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10]\n",
      "Training - Log Prob: 5.3087\n",
      "Validation - Log Prob: 5.8160\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, training: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "Epoch 11, validation: 100%|██████████| 4/4 [00:00<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 11]\n",
      "Training - Log Prob: 5.5220\n",
      "Validation - Log Prob: 4.9522\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, training: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "Epoch 12, validation: 100%|██████████| 4/4 [00:00<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12]\n",
      "Training - Log Prob: 5.6822\n",
      "Validation - Log Prob: 5.6409\n",
      "Current learning rates: [0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, training:   9%|▉         | 3/32 [00:01<00:16,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m optimizer = torch.optim.Adam(sin_model.parameters(), lr=\u001b[32m5e-4\u001b[39m)\n\u001b[32m      2\u001b[39m scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[32m      3\u001b[39m     optimizer, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m3\u001b[39m\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m sin_stuff = \u001b[43mtrain_npe_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msin_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain_Loader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVal_Loader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDingo_sin.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pycbc/Msci-GW/JHPY.py:733\u001b[39m, in \u001b[36mtrain_npe_model\u001b[39m\u001b[34m(model, optimizer, n_epochs, train_dloader, val_dloader, start_epoch, patience, scheduler, save_best_model, model_path, grad_clip_norm, dropout_rate)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_train, y_train \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dloader, desc=\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, training\u001b[39m\u001b[33m'\u001b[39m.format(epoch+\u001b[32m1\u001b[39m)):\n\u001b[32m    732\u001b[39m     optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     log_prob = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     loss = -log_prob.mean()  \u001b[38;5;66;03m# Negative log prob for gradient descent\u001b[39;00m\n\u001b[32m    736\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pycbc/Msci-GW/JHPY.py:521\u001b[39m, in \u001b[36mDINGOModel.forward\u001b[39m\u001b[34m(self, params, data)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[33;03mCompute log probability of parameters given data\u001b[39;00m\n\u001b[32m    510\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    518\u001b[39m \u001b[33;03m    log_prob: log p(params | data)\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    520\u001b[39m context = \u001b[38;5;28mself\u001b[39m.embedding_net(data)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pycbc/Msci-GW/JHPY.py:422\u001b[39m, in \u001b[36mNormalizingFlow.forward\u001b[39m\u001b[34m(self, params, context)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Apply flow transformations\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     z, log_det = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m     log_det_sum += log_det\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# Compute log probability under base distribution using PyTorch distributions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pycbc/Msci-GW/JHPY.py:152\u001b[39m, in \u001b[36mAffineCouplingLayer.forward\u001b[39m\u001b[34m(self, x, context, reverse)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Compute scale and translation\u001b[39;00m\n\u001b[32m    151\u001b[39m s = \u001b[38;5;28mself\u001b[39m.scale_net(scale_input)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtranslation_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslation_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Only apply to unmasked dimensions\u001b[39;00m\n\u001b[32m    155\u001b[39m s = s * (\u001b[32m1\u001b[39m - \u001b[38;5;28mself\u001b[39m.mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(sin_model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "sin_stuff = train_npe_model(sin_model, optimizer, 50, sin_data[\"Train_Loader\"], sin_data[\"Val_Loader\"], scheduler=scheduler, patience=5, dropout_rate=0.1, save_best_model=True, model_path=\"Dingo_sin.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
